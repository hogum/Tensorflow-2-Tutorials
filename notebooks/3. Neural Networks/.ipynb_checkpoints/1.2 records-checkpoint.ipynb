{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data TF Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary file format. Convenient for large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([20., 40, 60, 80, 120, 140, 160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = './records.tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_records(name, rec):\n",
    "    \"\"\"\n",
    "        Serialized data and writes to file\n",
    "    \"\"\"\n",
    "    writer = tf.io.TFRecordWriter(name)\n",
    "    feature = {}\n",
    "    \n",
    "    feature['data'] = tf.train.Feature(float_list=tf.train.FloatList(value=rec))\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    serialized = example.SerializeToString()\n",
    "    \n",
    "    writer.write(serialized)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_records(dataset_name, data)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(example):\n",
    "    \"\"\"\n",
    "        Decodes dataset read from file\n",
    "    \"\"\"\n",
    "    \n",
    "    keys_to_features = {'data': tf.io.FixedLenSequenceFeature([], dtype=tf.int64, allow_missing=True)}\n",
    "    parsed = tf.io.parse_single_example(serialized=example, features=keys_to_features)\n",
    "    \n",
    "    return parsed.get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (None,), types: tf.int64>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[7.6696546e-15 2.6288429e+20 1.2398926e-19 4.5699235e-22 2.0000000e+01\n",
      " 4.0000000e+01 6.0000000e+01 8.0000000e+01 1.2000000e+02 1.4000000e+02\n",
      " 1.6000000e+02], shape=(11,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    decoded = tf.compat.v1.decode_raw(item, out_type=tf.float32)\n",
    "    print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfs",
   "language": "python",
   "name": "tfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
