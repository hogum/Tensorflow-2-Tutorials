{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character based recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/1400/1400-0.txt\n",
      "1056768/1049619 [==============================] - 11s 11us/step\n"
     ]
    }
   ],
   "source": [
    "file_url = 'https://www.gutenberg.org/files/1400/1400-0.txt'\n",
    "file_path = tf.keras.utils.get_file('1400-0.txt', file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(file_path).read()\n",
    "# Strip off instruction text\n",
    "story_text = text[824:18781]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: 88\n",
      " ['\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ê', 'ô', '“', '”', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "# get unique characters\n",
    "vocab = sorted(set(text))\n",
    "print(f'Unique characters: {len(vocab)}\\n {vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign index values to each character\n",
    "char_to_index = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the text to array of integers\n",
    "\n",
    "text_as_int = np.asarray([char_to_index[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013445,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f Great Expectations\n",
      "f:62  :1 G:35 r:74 e:61 a:57 t:76  :1 E:33 x:80 p:72 e:61 c:59 t:76 a:57 t:76 i:65 o:71 n:70 s:75 "
     ]
    }
   ],
   "source": [
    "# show character mapping\n",
    "\n",
    "start, stop = 30, 50\n",
    "\n",
    "print(text[start:stop])\n",
    "for i in range(start, stop):\n",
    "    print(f'{text[i]}:{text_as_int[i]}', end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare an input dataset from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Great Expectations, by Charles Dickens"
     ]
    }
   ],
   "source": [
    "# Create input Dataset\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for idx in char_dataset.take(70):\n",
    "    print(idx_to_char[idx], end= '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch data for training\n",
    "\n",
    "sequence_len = 80\n",
    "examples_per_epoch = len(text) / sequence_len\n",
    "\n",
    "sequences = char_dataset.batch(batch_size=sequence_len + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(text_chunk):\n",
    "    \"\"\"\n",
    "        Creates the input and target data by shifting one\n",
    "        character to the right\n",
    "        \n",
    "        Example: Outside -> utsider\n",
    "    \"\"\"\n",
    "    input_txt = text_chunk[:-1]\n",
    "    target_txt = text_chunk[1:]\n",
    "    \n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Display the input and target data\n",
    "\n",
    "- `dataset.take(n)`returns `n` batches.\n",
    "- The batch size = `sequence_len` characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ﻿The Project Gutenberg EBook of Great Expectations, by Charles Dickens\n",
      "\n",
      "This eBo\n",
      "Target:  The Project Gutenberg EBook of Great Expectations, by Charles Dickens\n",
      "\n",
      "This eBoo\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# display for 2 batches\n",
    "input_example, target_example = [], []\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "    print(r'Input: ', ''.join(idx_to_char[input.numpy()]))\n",
    "    print(r'Target: ', ''.join(idx_to_char[target.numpy()]))\n",
    "    print('----------------')\n",
    "    \n",
    "    input_example.append(input.numpy())\n",
    "    target_example.append(target.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display input and the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "\n",
      "input: ﻿ (87)\n",
      "target:  T (48)\n",
      "step: 1\n",
      "\n",
      "input: T (48)\n",
      "target:  h (64)\n",
      "step: 2\n",
      "\n",
      "input: h (64)\n",
      "target:  e (61)\n",
      "step: 3\n",
      "\n",
      "input: e (61)\n",
      "target:    (1)\n",
      "step: 4\n",
      "\n",
      "input:   (1)\n",
      "target:  P (44)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[0][:5], target_example[0][:5])):\n",
    "    print(f'step: {i}\\n')\n",
    "    print(f'input: {idx_to_char[input_idx]} ({input_idx})')\n",
    "    print(f'target:  {idx_to_char[target_idx]} ({target_idx})')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # chars in batch\n",
    "steps_per_epoch = examples_per_epoch // batch_size\n",
    "buffer_size = text_as_int.size\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# re-feed data to the model from the beginning\n",
    "dataset = dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model has the layers:\n",
    "\n",
    "    a) Embedding layers - Lookup table of vectors\n",
    "    \n",
    "    b) Gate Recurrent Unit\n",
    "    \n",
    "    c) Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)\n",
    "embedding_dimension = 256\n",
    "recurrent_nn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    recurrent_nn = tf.keras.layers.CuDNNGRU\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    from functools import partial\n",
    "    recurrent_nn = partial(tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layers = [tf.keras.layers.Embedding(input_dim=vocab_len,\n",
    "                                        output_dim=embedding_dimension,\n",
    "                                        batch_input_shape=[batch_size, None]\n",
    "                                       ),\n",
    "              recurrent_nn(units=recurrent_nn_units,\n",
    "                          return_sequences=True,\n",
    "                          stateful=True),\n",
    "              tf.keras.layers.Dense(vocab_len)\n",
    "             ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7efe39b9a4d0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (64, 80, 88)   # [Batch, sequence_len, vocab_len]\n"
     ]
    }
   ],
   "source": [
    "# Check output shape of model\n",
    "\n",
    "for input_batch, target_batch in dataset.take(1):\n",
    "    batch_pred = model(input_batch)\n",
    "    print(f'Output shape: {batch_pred.shape}   # [Batch, sequence_len, vocab_len]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (64, None, 256)           22528     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 88)            90200     \n",
      "=================================================================\n",
      "Total params: 4,051,032\n",
      "Trainable params: 4,051,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfs",
   "language": "python",
   "name": "tfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
